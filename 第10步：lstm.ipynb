{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T12:08:39.715199Z",
     "start_time": "2025-05-11T12:08:39.651262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import  torch\n",
    "print(torch.cuda.is_available())"
   ],
   "id": "164ec17300f9ca25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T12:16:31.566039Z",
     "start_time": "2025-05-11T12:16:30.411656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 0. 检测设备 & cuDNN 调优\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "torch.backends.cudnn.benchmark = True  # 如果输入尺寸固定，可加速卷积\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1. 读取并排序数据\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "df = pd.read_csv('最终干净的数据改.csv')      # 替换为你的文件路径\n",
    "df = df.sort_values('tradeTime').reset_index(drop=True)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 2. 特征选取 & 归一化\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "feature_cols = [\n",
    "    'followers','square','livingRoom','drawingRoom','kitchen','bathRoom',\n",
    "    'buildingType','constructionTime','renovationCondition','buildingStructure',\n",
    "    'ladderRatio','elevator','fiveYearsProperty','subway','district',\n",
    "    'communityAverage','distance','Age','floorType','floorHeight',\n",
    "    'room_count','room_ratio','north_south',\n",
    "    'Investment in residential real estate development in Beijing',\n",
    "    'Inflation rate'\n",
    "]\n",
    "target_col = ['price_log']\n",
    "\n",
    "# 提取数据并归一化到 [0,1]\n",
    "data = df[feature_cols + target_col].values.astype(float)\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 3. 构造时序样本（滑动窗口）\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def create_sequences(data, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        X.append(data[i:i+n_steps, :-1])      # n_steps × 特征数\n",
    "        y.append(data[i+n_steps, -1])         # 对应下一步的 price_log\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "n_steps = 3\n",
    "X, y = create_sequences(data_scaled, n_steps)\n",
    "# 现在 X.shape = (样本数, n_steps, 特征数)， y.shape = (样本数,)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 4. 划分训练/验证集\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "split = int(len(X) * 0.8)\n",
    "X_train, X_val = X[:split], X[split:]\n",
    "y_train, y_val = y[:split], y[split:]\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 5. Dataset & DataLoader（启用 pin_memory 加速 GPU 拷贝）\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).float().unsqueeze(1)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(\n",
    "    SeqDataset(X_train, y_train),\n",
    "    batch_size=batch_size, shuffle=True,\n",
    "    pin_memory=False, num_workers=0\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    SeqDataset(X_val, y_val),\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    pin_memory=False, num_workers=0\n",
    ")"
   ],
   "id": "a6acfcdc7e3d041",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T12:35:43.373323Z",
     "start_time": "2025-05-11T12:16:34.899865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 6. 定义 LSTMRegressor 模型\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden1=64, hidden2=32, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.lstm2 = nn.LSTM(hidden1, hidden2, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden2, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm1(x)      # (batch, seq, hidden1)\n",
    "        out = self.dropout1(out)\n",
    "        out, _ = self.lstm2(out)    # (batch, seq, hidden2)\n",
    "        out = self.dropout2(out)\n",
    "        out = out[:, -1, :]         # 取最后时间步的隐藏状态\n",
    "        return self.fc(out)\n",
    "\n",
    "model = LSTMRegressor(input_size=X.shape[2]).to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 7. 训练循环 & 早停\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "if __name__ == '__main__':  # 添加这个部分\n",
    "    epochs = 20\n",
    "    best_val_loss = float('inf')\n",
    "    patience, wait = 10, 0\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            preds = model(xb)\n",
    "            val_losses.append(criterion(preds, yb).item())\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "    val_loss = np.mean(val_losses)\n",
    "    print(f'Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping. Restoring best model.\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 8. 预测 & 逆归一化\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for xb, _ in val_loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        all_preds.extend(model(xb).cpu().numpy().flatten())\n",
    "\n",
    "# 构造 dummy 用于 inverse_transform\n",
    "dummy_pred = np.zeros((len(all_preds), data.shape[1]))\n",
    "dummy_pred[:, -1] = all_preds\n",
    "pred_price_log = scaler.inverse_transform(dummy_pred)[:, -1]\n",
    "\n",
    "y_flat = y_val.flatten()\n",
    "dummy_true = np.zeros((len(y_flat), data.shape[1]))\n",
    "dummy_true[:, -1] = y_flat\n",
    "true_price_log = scaler.inverse_transform(dummy_true)[:, -1]\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 9. 评估：RMSE & R²\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "rmse = np.sqrt(mean_squared_error(true_price_log, pred_price_log))\n",
    "r2   = r2_score(true_price_log, pred_price_log)\n",
    "print(f'Validation RMSE (log-price) = {rmse:.4f}')\n",
    "print(f'Validation R²     (log-price) = {r2:.4f}')\n"
   ],
   "id": "11daaa279b4082ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.0134 | Val Loss: 0.0803\n",
      "Epoch 002 | Train Loss: 0.0121 | Val Loss: 0.0839\n",
      "Epoch 003 | Train Loss: 0.0117 | Val Loss: 0.1128\n",
      "Epoch 004 | Train Loss: 0.0114 | Val Loss: 0.1114\n",
      "Epoch 005 | Train Loss: 0.0112 | Val Loss: 0.1196\n",
      "Epoch 006 | Train Loss: 0.0111 | Val Loss: 0.1054\n",
      "Epoch 007 | Train Loss: 0.0110 | Val Loss: 0.1158\n",
      "Epoch 008 | Train Loss: 0.0109 | Val Loss: 0.0879\n",
      "Epoch 009 | Train Loss: 0.0108 | Val Loss: 0.0836\n",
      "Epoch 010 | Train Loss: 0.0107 | Val Loss: 0.0851\n",
      "Epoch 011 | Train Loss: 0.0107 | Val Loss: 0.0857\n",
      "Early stopping. Restoring best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_50756\\4240936155.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE (log-price) = 0.7688\n",
      "Validation R²     (log-price) = -3.6117\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
